{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da81471-5a53-4a19-9f0c-57acee88cee0",
   "metadata": {},
   "source": [
    "## Amplitude Analytics RAG System\n",
    " \n",
    "This notebook implements a RAG (Retrieval Augmented Generation) system for Amplitude analytics using:\n",
    "- ChromaDB for vector storage\n",
    "- Claude AI for natural language processing\n",
    "- Custom parsing for event documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227dd5a3-ea87-4501-9dd2-58b0d1518974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: anthropic in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (0.42.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.115.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (3.8.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (3.10.14)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from anthropic) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from anthropic) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.37.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\getapia\\appdata\\local\\anaconda3\\envs\\rag_project\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# ## Setup\n",
    "# First, let's install the required packages:\n",
    "!pip install chromadb anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059b995a-859a-40f0-b757-d59c6e0459f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import json\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2d6ad-1755-4644-bc95-0caa657b2962",
   "metadata": {},
   "source": [
    "### Event Documentation Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0aa01d-5666-49ea-925b-39e0db9314e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDocParser:\n",
    "    \"\"\"Parser for event documentation in markdown format.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_markdown_file(file_path: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Parse event documentation from a markdown file.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the markdown file\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing parsed event information\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        event_blocks = re.split(r'\\nEvent:', content)\n",
    "        event_blocks = [block for block in event_blocks if block.strip()]\n",
    "        \n",
    "        parsed_events = []\n",
    "        for block in event_blocks:\n",
    "            event_info = EventDocParser._parse_event_block(f\"Event:{block}\")\n",
    "            if event_info:\n",
    "                parsed_events.append(event_info)\n",
    "                \n",
    "        return parsed_events\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_event_block(block: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse a single event block.\"\"\"\n",
    "        try:\n",
    "            event_match = re.search(r'Event:\\s*(.+?)(?:\\n|$)', block)\n",
    "            if not event_match:\n",
    "                return None\n",
    "            event_name = event_match.group(1).strip()\n",
    "            \n",
    "            desc_match = re.search(r'Description:\\s*(.+?)(?:\\n[A-Za-z]|$)', block)\n",
    "            description = desc_match.group(1).strip() if desc_match else \"\"\n",
    "            \n",
    "            attributes = {}\n",
    "            attr_section = re.search(r'Attributes:\\n((?:  - .+\\n?)+)', block)\n",
    "            if attr_section:\n",
    "                attr_lines = attr_section.group(1).split('\\n')\n",
    "                for line in attr_lines:\n",
    "                    if line.strip().startswith('-'):\n",
    "                        attr_match = re.search(r'-\\s*(\\w+)\\s*\\((\\w+)\\):\\s*(.+)', line)\n",
    "                        if attr_match:\n",
    "                            name, attr_type, desc = attr_match.groups()\n",
    "                            attributes[name] = {\n",
    "                                \"type\": attr_type.strip(),\n",
    "                                \"description\": desc.strip()\n",
    "                            }\n",
    "            \n",
    "            return {\n",
    "                \"event_name\": event_name,\n",
    "                \"description\": description,\n",
    "                \"attributes\": attributes\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing event block: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232530db-4527-4ce7-a6ac-cc3ccc99607a",
   "metadata": {},
   "source": [
    "## Main RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0daae2bd-0186-480f-a8af-9df7578a2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmplitudeAnalyticsRAG:\n",
    "    def __init__(self, \n",
    "                 collection_name: str = \"amplitude_docs\",\n",
    "                 anthropic_api_key: Optional[str] = None):\n",
    "        \"\"\"Initialize the RAG system.\"\"\"\n",
    "        self.client = chromadb.Client()\n",
    "        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "        self.debugging = False\n",
    "        \n",
    "        try:\n",
    "            self.collection = self.client.get_collection(\n",
    "                name=collection_name,\n",
    "                embedding_function=self.embedding_fn\n",
    "            )\n",
    "            print(f\"Retrieved existing collection: {collection_name}\")\n",
    "        except:\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=collection_name,\n",
    "                embedding_function=self.embedding_fn\n",
    "            )\n",
    "            print(f\"Created new collection: {collection_name}\")\n",
    "\n",
    "        self.anthropic = Anthropic(\n",
    "            api_key=anthropic_api_key or os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        )\n",
    "\n",
    "    def process_markdown_documentation(self, markdown_file_path: str) -> int:\n",
    "        \"\"\"Process event documentation with enhanced attribute storage.\"\"\"\n",
    "        try:\n",
    "            events = EventDocParser.parse_markdown_file(markdown_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing markdown file: {e}\")\n",
    "            return 0\n",
    "        if self.debugging:\n",
    "            print(f\"Found {len(events)} events to process\")\n",
    "    \n",
    "        for i, event in enumerate(events):\n",
    "            # Create a more comprehensive and searchable document content\n",
    "            doc_text = f\"\"\"\n",
    "            Event Documentation:\n",
    "            Event Name: {event['event_name']}\n",
    "            \n",
    "            Description: {event['event_name']} - {event['description']}\n",
    "            \n",
    "            This event can be used for analyzing:\n",
    "            - Video tracking and analytics\n",
    "            - User engagement metrics\n",
    "            - Content performance monitoring\n",
    "            \n",
    "            Available Attributes for Analysis:\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add attributes with more context\n",
    "            for attr_name, attr_info in event['attributes'].items():\n",
    "                doc_text += f\"\\n- {attr_name} ({attr_info['type']}): {attr_info['description']}\"\n",
    "                # Add usage hints for common attributes\n",
    "                if 'video' in attr_name.lower():\n",
    "                    doc_text += \"\\n  Use this attribute for video-specific analysis and filtering.\"\n",
    "                if 'duration' in attr_name.lower():\n",
    "                    doc_text += \"\\n  Important for time-based analysis and completion rates.\"\n",
    "                if 'type' in attr_name.lower():\n",
    "                    doc_text += \"\\n  Useful for segmentation and comparative analysis.\"\n",
    "            \n",
    "            # Add common use cases section\n",
    "            doc_text += \"\"\"\n",
    "            \n",
    "            Common Analytics Use Cases:\n",
    "            - Tracking video completion rates\n",
    "            - Analyzing user engagement patterns\n",
    "            - Measuring content performance\n",
    "            - Segmenting by video types\n",
    "            - Monitoring viewer behavior\n",
    "            \"\"\"\n",
    "            \n",
    "            # Store in ChromaDB with enhanced metadata\n",
    "            try:\n",
    "                metadata = {\n",
    "                    \"event_name\": event['event_name'],\n",
    "                    \"type\": \"event_documentation\",\n",
    "                    \"attribute_count\": len(event['attributes']),\n",
    "                    \"attributes\": json.dumps({\n",
    "                        name: {\n",
    "                            \"type\": info[\"type\"],\n",
    "                            \"description\": info[\"description\"]\n",
    "                        }\n",
    "                        for name, info in event['attributes'].items()\n",
    "                    }),\n",
    "                    \"keywords\": \"video, completion, rates, analytics, tracking, metrics, engagement\"\n",
    "                }\n",
    "\n",
    "                if self.debugging:\n",
    "                    print(f\"Storing event {i+1}/{len(events)}: {event['event_name']}\")\n",
    "                \n",
    "                self.collection.add(\n",
    "                    documents=[doc_text],\n",
    "                    metadatas=[metadata],\n",
    "                    ids=[f\"doc_{i}\"]\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error storing event {event['event_name']}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return len(events)\n",
    "\n",
    "    def get_amplitude_guidance(self, query: str) -> str:\n",
    "        \"\"\"Get enhanced Amplitude implementation guidance using Claude.\"\"\"\n",
    "        try:\n",
    "            count = self.collection.count()\n",
    "            if count == 0:\n",
    "                return \"No documentation has been loaded into the system yet. Please process your documentation first.\"\n",
    "\n",
    "            if self.debugging:\n",
    "                print(f\"\\nSearching collection with {count} documents...\")\n",
    "            \n",
    "            # Query including all necessary fields\n",
    "            results = self.collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=min(10, count),\n",
    "                include=['metadatas', 'distances', 'documents'] \n",
    "            )\n",
    "            \n",
    "            if not results.get('documents') or not results['documents'][0]:\n",
    "                if self.debugging:\n",
    "                    print(\"No documents found in query results\")\n",
    "                return \"No relevant documentation found for your query. Please try a different question.\"\n",
    "    \n",
    "            relevant_docs = results['documents'][0]\n",
    "            relevant_metadata = results['metadatas'][0]\n",
    "            distances = results['distances'][0]\n",
    "\n",
    "            if self.debugging:\n",
    "                print(f\"\\nFound {len(relevant_docs)} relevant documents\")\n",
    "            \n",
    "            # Create context with ranked results\n",
    "            context_parts = [\"# Available Event Documentation\\n\"]\n",
    "            \n",
    "            for doc, meta, distance in zip(relevant_docs, relevant_metadata, distances):\n",
    "                similarity = 1 - distance  # Convert distance to similarity score\n",
    "                context_parts.append(f\"\\nRelevance Score: {similarity:.4f}\")\n",
    "                context_parts.append(doc)\n",
    "                \n",
    "                if meta and 'attributes' in meta:\n",
    "                    try:\n",
    "                        attributes = json.loads(meta['attributes'])\n",
    "                        context_parts.append(\"\\nDetailed Attributes:\")\n",
    "                        for attr_name, attr_info in attributes.items():\n",
    "                            context_parts.append(\n",
    "                                f\"- {attr_name} ({attr_info['type']}): {attr_info['description']}\"\n",
    "                            )\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Warning: Could not parse attributes JSON for document\")\n",
    "            \n",
    "            context_parts.extend([\"\\n# Query\", query])\n",
    "            context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "            if self.debugging:\n",
    "                print(f\"\\nPrepared context with {len(relevant_docs)} documents\")\n",
    "    \n",
    "            prompt = f\"\"\"You are an Amplitude analytics expert. Using the provided event documentation and detailed \n",
    "            attribute information, create comprehensive implementation steps for analyzing video metrics. \n",
    "            Focus specifically on the user's query while utilizing the available events and attributes.\n",
    "    \n",
    "            Include:\n",
    "            1. The most appropriate chart type and why\n",
    "            2. Exact events to use (from the provided documentation)\n",
    "            3. Required filters and their configuration, using the specific attributes available\n",
    "            4. How to set up grouping using available attributes\n",
    "            5. Additional settings or considerations\n",
    "            6. Preview of expected insights\n",
    "            7. Any relevant attribute combinations that could enhance the analysis\n",
    "    \n",
    "            User Query: {query}\n",
    "    \n",
    "            Available Documentation and Attributes:\n",
    "            {context}\n",
    "    \n",
    "            Please provide a detailed, step-by-step response that someone could follow to implement \n",
    "            this analysis in Amplitude. Include both technical steps and explanatory notes.\"\"\"\n",
    "    \n",
    "            response = self.anthropic.messages.create(\n",
    "                model=\"claude-3-opus-20240229\",\n",
    "                max_tokens=1000,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            return response.content\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"Debug - Full error: {str(e)}\")\n",
    "            return f\"Error processing query: {str(e)}\"\n",
    "\n",
    "    def get_event_attributes(self, event_name: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Get detailed attribute information for a specific event.\n",
    "        \n",
    "        Args:\n",
    "            event_name: Name of the event to look up (with or without 'Event:' prefix)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing event details and attributes\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Clean up the event name by removing 'Event:' if present\n",
    "            clean_event_name = event_name.replace('Event:', '').strip()\n",
    "\n",
    "            print(f\"Searching for event: {clean_event_name}\")  # Debug info\n",
    "            \n",
    "            # Query collection\n",
    "            results = self.collection.get(\n",
    "                where={\"event_name\": clean_event_name},\n",
    "                include=['metadatas']\n",
    "            )\n",
    "            \n",
    "            if not results['metadatas']:\n",
    "                # If not found, try alternative format\n",
    "                results = self.collection.get(\n",
    "                    where={\"event_name\": f\"Event: {clean_event_name}\"},\n",
    "                    include=['metadatas']\n",
    "                )\n",
    "            \n",
    "            if not results['metadatas']:\n",
    "                return {\n",
    "                    \"error\": f\"Event not found: {clean_event_name}\",\n",
    "                    \"searched_names\": [clean_event_name, f\"Event: {clean_event_name}\"]\n",
    "                }\n",
    "                \n",
    "            metadata = results['metadatas'][0]\n",
    "            if 'attributes' in metadata:\n",
    "                return {\n",
    "                    \"event_name\": clean_event_name,\n",
    "                    \"attributes\": json.loads(metadata['attributes'])\n",
    "                }\n",
    "            \n",
    "            return {\"error\": \"No attribute information found\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def get_collection_stats(self) -> Dict:\n",
    "        \"\"\"Get enhanced statistics about the stored documentation.\"\"\"\n",
    "        try:\n",
    "            count = self.collection.count()\n",
    "            \n",
    "            sample = self.collection.get(\n",
    "                limit=5,\n",
    "                include=['documents', 'metadatas']\n",
    "            )\n",
    "            \n",
    "            stats = {\n",
    "                \"total_events\": count,\n",
    "                \"sample_events\": [\n",
    "                    {\n",
    "                        \"event\": meta['event_name'],\n",
    "                        \"attribute_count\": meta.get('attribute_count', 0),\n",
    "                        \"attributes\": json.loads(meta['attributes']) if 'attributes' in meta else {}\n",
    "                    }\n",
    "                    for meta in sample['metadatas']\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting collection stats: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def debug_collection(self):\n",
    "        \"\"\"Debug method to check what's actually stored in the collection.\"\"\"\n",
    "        try:\n",
    "            # Get count\n",
    "            count = self.collection.count()\n",
    "            print(f\"\\nTotal documents in collection: {count}\")\n",
    "            \n",
    "            if count > 0:\n",
    "                # Get all documents\n",
    "                results = self.collection.get(\n",
    "                    include=['documents', 'metadatas'],\n",
    "                    limit=count\n",
    "                )\n",
    "                \n",
    "                print(\"\\nSample of stored documents:\")\n",
    "                for i, (doc, meta) in enumerate(zip(results['documents'], results['metadatas'])):\n",
    "                    print(f\"\\n--- Document {i+1} ---\")\n",
    "                    print(\"Metadata:\", json.dumps(meta, indent=2))\n",
    "                    print(\"First 200 chars of document:\", doc[:200])\n",
    "                    if i >= 2:  # Show just first 3 documents\n",
    "                        break\n",
    "                        \n",
    "                # Try a simple query\n",
    "                test_query = \"video\"\n",
    "                print(f\"\\nTesting simple query: '{test_query}'\")\n",
    "                query_results = self.collection.query(\n",
    "                    query_texts=[test_query],\n",
    "                    n_results=1\n",
    "                )\n",
    "                print(\"Query results:\", json.dumps(query_results, indent=2))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Debug error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9a835d-b554-44d1-8b76-a2e738728042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_blocks(text_blocks):\n",
    "    for block in text_blocks:\n",
    "        if hasattr(block, 'text'):\n",
    "            text = block.text\n",
    "            # Split text into steps based on the pattern \"\\n\\n<number>.\"\n",
    "            steps = re.split(r'\\n\\n(\\d+)\\.', text)\n",
    "            \n",
    "            if steps[0].strip():  # Print intro if any\n",
    "                print(\"\\nIntroduction:\")\n",
    "                print(steps[0].strip())\n",
    "\n",
    "            for i in range(1, len(steps), 2):\n",
    "                step_number = steps[i]\n",
    "                step_text = steps[i+1].strip() if i+1 < len(steps) else \"\"\n",
    "                print(f\"\\nStep {step_number}:\")\n",
    "                print(step_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0518d5b-e6c6-407c-a286-bf2646b6478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_from_json(file_path):\n",
    "    \"\"\"Loads security keys from a JSON file and sets them as environment variables.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            secrets = json.load(file)\n",
    "            for key, value in secrets.items():\n",
    "                os.environ[key] = value\n",
    "                print(f\"Loaded {key} into environment variables\")  # Optional, for debugging\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not parse {file_path}. Ensure it is valid JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e0444c-7cac-4628-b8e2-3c383c40a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ANTHROPIC_API_KEY into environment variables\n"
     ]
    }
   ],
   "source": [
    "load_env_from_json('secrets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94ebf339-a586-4933-95df-1899e0701be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new collection: amplitude_docs\n"
     ]
    }
   ],
   "source": [
    "rag = AmplitudeAnalyticsRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7cb16f-52ab-43ba-97b6-bb18e4c4b6fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 41 events\n"
     ]
    }
   ],
   "source": [
    "documentation_path = \"MT-DataSchema.md\"  # Update this path\n",
    "num_events = rag.process_markdown_documentation(documentation_path)\n",
    "print(f\"Processed {num_events} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790e69c6-97d4-4395-a8e8-8970c4b9f54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection Statistics:\n",
      "{\n",
      "  \"total_events\": 41,\n",
      "  \"sample_events\": [\n",
      "    {\n",
      "      \"event\": \"Event: Video 75% Complete\",\n",
      "      \"attribute_count\": 10,\n",
      "      \"attributes\": {\n",
      "        \"video_session_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"Video session unique for each video\"\n",
      "        },\n",
      "        \"video_casted\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"A boolean representing whether the video is currently casted\"\n",
      "        },\n",
      "        \"video_duration\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The duration of the video in seconds\"\n",
      "        },\n",
      "        \"video_title\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The title of the video\"\n",
      "        },\n",
      "        \"video_source\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The source of the video like \\\"kaltura\\\", \\\"webiny\\\", etc\"\n",
      "        },\n",
      "        \"video_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The ID of the video asset from the platform source\"\n",
      "        },\n",
      "        \"video_publication_date\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The publication date for the video in ISO standard format.\"\n",
      "        },\n",
      "        \"video_type\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The type of video: long form, short form, fast tv, etc\"\n",
      "        },\n",
      "        \"playhead_position\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The position of the playhead at the time the event occurred.\"\n",
      "        },\n",
      "        \"platform_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the platform\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"event\": \"Video View Ended\",\n",
      "      \"attribute_count\": 22,\n",
      "      \"attributes\": {\n",
      "        \"video_channel_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the FAST TV channel the video is being watched on.\"\n",
      "        },\n",
      "        \"video_session_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"Video session unique for each video\"\n",
      "        },\n",
      "        \"max_playhead_position\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The maximum playhead position for the video \\\"session\\\". Can be higher than the playhead_position in the Video View Ended event due to scrubbing.\"\n",
      "        },\n",
      "        \"video_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The ID of the video asset from the platform source\"\n",
      "        },\n",
      "        \"total_ads_capacity\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The total potential number of ads that could have been viewed based on the ad serving rules.\"\n",
      "        },\n",
      "        \"total_ad_time\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The total number of seconds spent watching ads.\"\n",
      "        },\n",
      "        \"total_watch_time\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The total number of seconds a user spent actively watching the video content.\"\n",
      "        },\n",
      "        \"video_season_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name or number of the season if applicable; else \\\"0\\\"\"\n",
      "        },\n",
      "        \"video_duration\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The duration of the video in seconds\"\n",
      "        },\n",
      "        \"video_casted\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"A boolean representing whether the video is currently casted\"\n",
      "        },\n",
      "        \"playhead_position\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The position of the playhead at the time the event occurred.\"\n",
      "        },\n",
      "        \"video_type\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The type of video: long form, short form, fast tv, etc\"\n",
      "        },\n",
      "        \"total_session_time\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The total number of seconds a user spent on the same video including pause time and active watch time.\"\n",
      "        },\n",
      "        \"total_ads_viewed\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The total number of ads viewed.\"\n",
      "        },\n",
      "        \"video_source\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The source of the video like \\\"kaltura\\\", \\\"webiny\\\", etc\"\n",
      "        },\n",
      "        \"video_publication_date\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The publication date for the video in ISO standard format.\"\n",
      "        },\n",
      "        \"video_title\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The title of the video\"\n",
      "        },\n",
      "        \"video_show_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the show, if applicable.\"\n",
      "        },\n",
      "        \"video_episode_number\": {\n",
      "          \"type\": \"decimal\",\n",
      "          \"description\": \"The number of the episode. (Will be \\\"0\\\" if not numbered).\"\n",
      "        },\n",
      "        \"video_completed\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"A true or false value representing whether a user's max_playhead_position ever reached 90% or more of the video_duration.\"\n",
      "        },\n",
      "        \"video_show_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The ID of the show, if applicable.\"\n",
      "        },\n",
      "        \"platform_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the platform\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"event\": \"Click - Event Calendar\",\n",
      "      \"attribute_count\": 11,\n",
      "      \"attributes\": {\n",
      "        \"element_content\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The content of the element being clicked. For rail clicks this would be the show name. For CTAs it could be the button text.\"\n",
      "        },\n",
      "        \"event_group\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The more broad group of events this belongs with. For example login type buttons may belong to an Authentication event_group.\"\n",
      "        },\n",
      "        \"element_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the specific clickable element. This is more specific than event_name.\"\n",
      "        },\n",
      "        \"event_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The more generic name of the event which can be triggered by multiple UI elements.\"\n",
      "        },\n",
      "        \"element_link\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The destination URL (href) of the clicked element\"\n",
      "        },\n",
      "        \"element_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The NextWeb ID of the element. Used for the Click config file.\"\n",
      "        },\n",
      "        \"element_parent\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the parent container where the clicked element is located.\"\n",
      "        },\n",
      "        \"mp_event_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"This is used for creating the event names in the mParticle data plan instead of the name in Anamap\"\n",
      "        },\n",
      "        \"element_position\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The position number of the element clicked. Ex: If the element parent is a rail then this will be the position number of the element inside the rail.\"\n",
      "        },\n",
      "        \"element_path\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"A Javascript selector path that can be used in document.querySelector to find the element on the page.\"\n",
      "        },\n",
      "        \"platform_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the platform\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"event\": \"Click - Join Newsletter\",\n",
      "      \"attribute_count\": 11,\n",
      "      \"attributes\": {\n",
      "        \"element_position\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The position number of the element clicked. Ex: If the element parent is a rail then this will be the position number of the element inside the rail.\"\n",
      "        },\n",
      "        \"element_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The NextWeb ID of the element. Used for the Click config file.\"\n",
      "        },\n",
      "        \"element_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the specific clickable element. This is more specific than event_name.\"\n",
      "        },\n",
      "        \"element_content\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The content of the element being clicked. For rail clicks this would be the show name. For CTAs it could be the button text.\"\n",
      "        },\n",
      "        \"element_path\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"A Javascript selector path that can be used in document.querySelector to find the element on the page.\"\n",
      "        },\n",
      "        \"element_parent\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the parent container where the clicked element is located.\"\n",
      "        },\n",
      "        \"event_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The more generic name of the event which can be triggered by multiple UI elements.\"\n",
      "        },\n",
      "        \"event_group\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The more broad group of events this belongs with. For example login type buttons may belong to an Authentication event_group.\"\n",
      "        },\n",
      "        \"element_link\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The destination URL (href) of the clicked element\"\n",
      "        },\n",
      "        \"mp_event_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"This is used for creating the event names in the mParticle data plan instead of the name in Anamap\"\n",
      "        },\n",
      "        \"platform_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the platform\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"event\": \"Click - Article Strip\",\n",
      "      \"attribute_count\": 11,\n",
      "      \"attributes\": {\n",
      "        \"event_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The more generic name of the event which can be triggered by multiple UI elements.\"\n",
      "        },\n",
      "        \"element_position\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The position number of the element clicked. Ex: If the element parent is a rail then this will be the position number of the element inside the rail.\"\n",
      "        },\n",
      "        \"element_id\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The NextWeb ID of the element. Used for the Click config file.\"\n",
      "        },\n",
      "        \"element_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the specific clickable element. This is more specific than event_name.\"\n",
      "        },\n",
      "        \"mp_event_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"This is used for creating the event names in the mParticle data plan instead of the name in Anamap\"\n",
      "        },\n",
      "        \"element_path\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"A Javascript selector path that can be used in document.querySelector to find the element on the page.\"\n",
      "        },\n",
      "        \"element_link\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The destination URL (href) of the clicked element\"\n",
      "        },\n",
      "        \"element_parent\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the parent container where the clicked element is located.\"\n",
      "        },\n",
      "        \"element_content\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The content of the element being clicked. For rail clicks this would be the show name. For CTAs it could be the button text.\"\n",
      "        },\n",
      "        \"event_group\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The more broad group of events this belongs with. For example login type buttons may belong to an Authentication event_group.\"\n",
      "        },\n",
      "        \"platform_name\": {\n",
      "          \"type\": \"text\",\n",
      "          \"description\": \"The name of the platform\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "stats = rag.get_collection_stats()\n",
    "print(\"\\nCollection Statistics:\")\n",
    "print(json.dumps(stats, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "748d9b34-5550-40a3-bb35-70bd60b2348a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for event: Video 75% Complete\n",
      "\n",
      "Attributes for Video 75% Complete:\n",
      "{\n",
      "  \"event_name\": \"Video 75% Complete\",\n",
      "  \"attributes\": {\n",
      "    \"video_session_id\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"Video session unique for each video\"\n",
      "    },\n",
      "    \"video_casted\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"A boolean representing whether the video is currently casted\"\n",
      "    },\n",
      "    \"video_duration\": {\n",
      "      \"type\": \"decimal\",\n",
      "      \"description\": \"The duration of the video in seconds\"\n",
      "    },\n",
      "    \"video_title\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"The title of the video\"\n",
      "    },\n",
      "    \"video_source\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"The source of the video like \\\"kaltura\\\", \\\"webiny\\\", etc\"\n",
      "    },\n",
      "    \"video_id\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"The ID of the video asset from the platform source\"\n",
      "    },\n",
      "    \"video_publication_date\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"The publication date for the video in ISO standard format.\"\n",
      "    },\n",
      "    \"video_type\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"The type of video: long form, short form, fast tv, etc\"\n",
      "    },\n",
      "    \"playhead_position\": {\n",
      "      \"type\": \"decimal\",\n",
      "      \"description\": \"The position of the playhead at the time the event occurred.\"\n",
      "    },\n",
      "    \"platform_name\": {\n",
      "      \"type\": \"text\",\n",
      "      \"description\": \"The name of the platform\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "event_name = \"Video 75% Complete\"  # Replace with an actual event name\n",
    "event_info = rag.get_event_attributes(event_name)\n",
    "print(f\"\\nAttributes for {event_name}:\")\n",
    "print(json.dumps(event_info, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8a713d-db98-49a5-90d1-17ba97d419d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction:\n",
      "Based on the provided event documentation and attributes, the most relevant event for tracking article visits appears to be the \"Viewed Page/Screen\" event. This event contains attributes like content_title, content_type, and content_publication_date that can help identify the top articles.\n",
      "\n",
      "Here are the step-by-step instructions to get the top 10 articles visited in the last 30 days using Amplitude:\n",
      "\n",
      "Step 1:\n",
      "Chart Type:\n",
      "   - Choose the \"Bar Chart\" visualization.\n",
      "   - This allows comparing the total visits for each article in a clear, visual way.\n",
      "\n",
      "Step 2:\n",
      "Event Selection: \n",
      "   - Select the \"Viewed Page/Screen\" event.\n",
      "   - This event represents a page view and contains attributes relevant to articles.\n",
      "\n",
      "Step 3:\n",
      "Filters:\n",
      "   - Add a filter for \"content_type\" = \"article\" to only include article page views.\n",
      "   - Set a filter for the last 30 days using the date picker or by specifying \"Last 30 days\" in the time range selector.\n",
      "   - This focuses the analysis on recent article visits.\n",
      "\n",
      "Step 4:\n",
      "Grouping:\n",
      "   - Group by the \"content_title\" attribute.\n",
      "   - This groups the results by each unique article title.\n",
      "\n",
      "Step 5:\n",
      "Additional Settings:\n",
      "   - In the chart settings, limit the number of articles shown to 10.\n",
      "   - Sort the articles by descending event count to show the top 10 most visited.\n",
      "   - Customize the chart title and labels as needed.\n",
      "\n",
      "Step 6:\n",
      "Insight Preview:\n",
      "   - The resulting bar chart will display the top 10 articles by name on the X-axis.\n",
      "   - The Y-axis will represent the total number of visits for each article.\n",
      "   - The articles will be sorted in descending order, with the most visited article at the top.\n",
      "\n",
      "Step 7:\n",
      "Additional Attribute Combinations:\n",
      "   - Consider adding a secondary grouping by \"content_section\" or \"content_category\" to understand which topics or categories are most popular.\n",
      "   - Use the \"content_publication_date\" attribute to analyze how article age influences visit count.\n",
      "   - Segment by device type or platform using the \"device_family\" or \"platform_name\" attributes to see if article preferences vary by device or platform.\n",
      "\n",
      "By following these steps, you can create a bar chart in Amplitude that shows the top 10 most visited articles over the last 30 days. The \"Viewed Page/Screen\" event, along with the \"content_title\" attribute and a 30-day time filter, are the key components for this analysis. \n",
      "\n",
      "Additional groupings and segmentation using attributes like content section, publication date, device, and platform can provide deeper insights into article performance and reader preferences.\n",
      "Elapsed time: 24.69683790 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query = \"How can I get the top 10 articles visited in the last 30 days?\"\n",
    "guidance = rag.get_amplitude_guidance(query)\n",
    "parse_text_blocks(guidance)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.8f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6068cb97-e5f3-480f-bb0c-7e1673fdb97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction:\n",
      "To track video engagement in Amplitude using the provided event documentation and attributes, follow these steps:\n",
      "\n",
      "Step 1:\n",
      "Chart Type: \n",
      "   - Use a Funnel chart to visualize the progression of users through key video milestones (25%, 50%, 75%, 100% completion).\n",
      "   - This chart type allows you to identify drop-off points and understand overall video engagement.\n",
      "\n",
      "Step 2:\n",
      "Events to Use:\n",
      "   - Video 25% Complete\n",
      "   - Video 50% Complete\n",
      "   - Video 75% Complete \n",
      "   - Video 100% Complete\n",
      "\n",
      "Step 3:\n",
      "Filters:\n",
      "   - Apply filters based on relevant attributes to focus on specific segments or video types.\n",
      "   - Example: Filter by \"video_type\" to analyze engagement for different video categories (e.g., long form, short form, fast tv).\n",
      "   - Use the \"video_source\" attribute to filter by video platform (e.g., kaltura, webiny) if needed.\n",
      "\n",
      "Step 4:\n",
      "Grouping:\n",
      "   - Group the funnel chart by the \"video_title\" attribute to compare engagement across different videos.\n",
      "   - This will help identify top-performing videos and those with lower engagement.\n",
      "\n",
      "Step 5:\n",
      "Additional Settings:\n",
      "   - Set the conversion window to a suitable time frame (e.g., 30 days) to capture users who complete the video milestones within that period.\n",
      "   - Customize the funnel chart's appearance and labels for better readability and understanding.\n",
      "\n",
      "Step 6:\n",
      "Expected Insights:\n",
      "   - Identify the overall completion rate for videos and spot any significant drop-off points.\n",
      "   - Compare engagement metrics across different video types, sources, or titles to understand performance variations.\n",
      "   - Gain insights into which videos effectively retain user engagement throughout their duration.\n",
      "\n",
      "Step 7:\n",
      "Attribute Combinations:\n",
      "   - Analyze engagement based on a combination of attributes like \"video_type\" and \"video_source\" to identify patterns across different segments.\n",
      "   - Utilize the \"video_duration\" attribute to normalize completion rates and compare engagement for videos of different lengths.\n",
      "   - Incorporate the \"video_publication_date\" attribute to track engagement trends over time and identify any seasonal or temporal patterns.\n",
      "\n",
      "By following these steps and leveraging the provided events and attributes, you can set up a comprehensive analysis of video engagement in Amplitude. The funnel chart will visualize the user journey through key video milestones, while filters and groupings will enable you to drill down into specific segments and compare performance across different dimensions.\n",
      "\n",
      "Remember to regularly review and iterate on your analysis based on the insights gained. Continuously monitor video engagement metrics to identify areas for improvement and optimize your video content strategy accordingly.\n",
      "\n",
      "If you have any further questions or need additional assistance, feel free to ask!\n",
      "Elapsed time: 23.26319742 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query = \"Show me how to track video engagement\"\n",
    "guidance = rag.get_amplitude_guidance(query)\n",
    "parse_text_blocks(guidance)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.8f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99115ec-73b5-4224-a4cc-5e515b6b8882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction:\n",
      "To track video engagement in Amplitude using the provided event documentation and attributes, follow these steps:\n",
      "\n",
      "Step 1:\n",
      "Chart Type:\n",
      "   - Use a \"Funnel\" chart to visualize the drop-off in user engagement at different video completion milestones.\n",
      "   - A funnel chart effectively shows the percentage of users who progress through each stage, helping identify where engagement declines.\n",
      "\n",
      "Step 2:\n",
      "Events to Use:\n",
      "   - Video View Started\n",
      "   - Video 25% Complete\n",
      "   - Video 50% Complete\n",
      "   - Video 75% Complete\n",
      "   - Video 100% Complete\n",
      "   These events capture key milestones in video playback and provide insights into engagement levels.\n",
      "\n",
      "Step 3:\n",
      "Filters:\n",
      "   - Apply filters to focus on specific video attributes:\n",
      "     - video_type: Filter by the type of video (e.g., \"long form\", \"short form\") to compare engagement across different formats.\n",
      "     - video_source: Filter by the source of the video (e.g., \"kaltura\", \"webiny\") to analyze performance across different platforms.\n",
      "     - video_publication_date: Filter by publication date range to examine engagement trends over time.\n",
      "   Filters help narrow down the analysis to specific subsets of videos.\n",
      "\n",
      "Step 4:\n",
      "Grouping:\n",
      "   - Group the funnel chart by the \"video_title\" attribute to compare engagement for individual videos.\n",
      "   - Alternatively, group by \"video_show_name\" to analyze engagement at the show level.\n",
      "   Grouping enables comparing engagement across different dimensions.\n",
      "\n",
      "Step 5:\n",
      "Additional Settings:\n",
      "   - Set the conversion window to a suitable timeframe (e.g., 30 days) to account for users who may not complete the video in one session.\n",
      "   - Customize the funnel stage names to reflect the completion milestones (e.g., \"Started\", \"25% Viewed\", \"50% Viewed\", \"75% Viewed\", \"Completed\").\n",
      "\n",
      "Step 6:\n",
      "Expected Insights:\n",
      "   - Identify the overall video completion rate and spot stages where significant drop-offs occur.\n",
      "   - Compare engagement rates across different video types, sources, or shows to identify top-performing content.\n",
      "   - Monitor engagement trends over time to assess the impact of content optimizations or changes in user behavior.\n",
      "\n",
      "Step 7:\n",
      "Attribute Combinations:\n",
      "   - Analyze engagement by combining \"video_type\" and \"video_duration\" to understand how video length affects completion rates for different formats.\n",
      "   - Combine \"video_show_name\" and \"video_season_name\" to compare engagement across seasons of a particular show.\n",
      "   - Mix and match attributes based on specific insights you want to uncover.\n",
      "\n",
      "By following these steps and leveraging the available events and attributes, you can set up comprehensive video engagement tracking in Amplitude. The funnel chart will provide a clear visualization of user drop-off at different completion stages, while filters and grouping options enable deep dive analysis. Keep an eye out for notable insights and trends, and experiment with different attribute combinations to gain a holistic understanding of video engagement patterns.\n",
      "\n",
      "Remember to regularly review and iterate on your analysis based on the insights gained and any changes in your video content strategy. Amplitude's flexibility allows for continuous refinement and exploration of video engagement data.\n",
      "Elapsed time: 27.73552513 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query = \"Show me how to track video engagement\"\n",
    "guidance = rag.get_amplitude_guidance(query)\n",
    "parse_text_blocks(guidance)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.8f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c956aad-5e3e-4527-8aae-4caf2bbf837c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction:\n",
      "Based on the provided event documentation and attribute details, there are several metrics available for comprehensive video analysis in Amplitude. Here are the implementation steps to set up video analysis:\n",
      "\n",
      "Step 1:\n",
      "Chart Type: \n",
      "   - Use a funnel chart to analyze video completion rates at different milestones (25%, 50%, 75%, 100%).\n",
      "   - Funnel charts effectively visualize user progression through sequential steps, making it ideal for tracking video completion.\n",
      "\n",
      "Step 2:\n",
      "Events to Use:\n",
      "   - \"Video 25% Complete\" \n",
      "   - \"Video 50% Complete\"\n",
      "   - \"Video 75% Complete\"\n",
      "   - \"Video 100% Complete\"\n",
      "   These events track when users reach specific milestones in the video playback.\n",
      "\n",
      "Step 3:\n",
      "Filters:\n",
      "   - Apply filters based on relevant attributes to narrow down the analysis:\n",
      "     - \"video_type\" to compare completion rates across different video types (e.g., long form, short form, fast tv)\n",
      "     - \"video_source\" to analyze performance by video source (e.g., kaltura, webiny)\n",
      "     - \"video_publication_date\" to examine completion trends over time\n",
      "     - \"platform_name\" to compare video engagement across different platforms\n",
      "\n",
      "Step 4:\n",
      "Grouping:\n",
      "   - Group the funnel chart by the \"video_title\" attribute to compare completion rates for individual videos.\n",
      "   - This will provide insights into which videos have higher engagement and completion rates.\n",
      "\n",
      "Step 5:\n",
      "Additional Settings:\n",
      "   - Set the conversion window to a suitable duration (e.g., 30 days) to account for users who may not complete the video in one session.\n",
      "   - Enable \"Account for Unequal Conversion Windows\" to ensure accurate completion rate calculations.\n",
      "\n",
      "Step 6:\n",
      "Expected Insights:\n",
      "   - Identify which video types, sources, or platforms have the highest completion rates.\n",
      "   - Determine if specific videos outperform others in terms of engagement and completion.\n",
      "   - Analyze trends in video completion over time based on publication dates.\n",
      "   - Discover potential drop-off points where users tend to disengage from the videos.\n",
      "\n",
      "Step 7:\n",
      "Attribute Combinations:\n",
      "   - Combine \"video_type\" and \"video_source\" attributes to gain deeper insights into completion rates by video type and source.\n",
      "   - Analyze completion rates based on \"video_duration\" to understand how video length influences user engagement.\n",
      "   - Segment analysis by \"video_show_name\" or \"video_season_name\" to compare performance across different shows or seasons.\n",
      "\n",
      "Additional Tips:\n",
      "- Use the \"Video Player Impression\" event to calculate the total number of video views and compare it against completion rates.\n",
      "- Leverage the \"Video View Started\" event to track the number of users who started watching each video.\n",
      "- Utilize the \"Video View Ended\" event to calculate average watch time, total watch time, and other engagement metrics.\n",
      "- Analyze the \"Video Ad Viewed\" event to assess ad performance and its impact on video completion rates.\n",
      "\n",
      "By following these steps and leveraging the available events and attributes, you can set up comprehensive video analysis in Amplitude. This will provide valuable insights into video performance, user engagement, and areas for optimization.\n",
      "\n",
      "Remember to regularly review and iterate on your analysis based on the insights gained to continuously improve the video content and user experience.\n",
      "Elapsed time: 30.18009067 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query = \"What metrics are available for video analysis?\"\n",
    "guidance = rag.get_amplitude_guidance(query)\n",
    "parse_text_blocks(guidance)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.8f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa456e0-575e-42ba-88e4-e1a9d9f3c07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
